{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Machine Translation with RNN\n",
    "\n",
    "We apply RNN to the language translation task, which is a typical seq to seq learning tastk. We will use a Encoder-Decoder architecture, where we use RNN models for both Encoder and Decoder parts. \n",
    "\n",
    "We will use the data from [the Tatoeba Project](http://www.manythings.org/anki/) and specifically, we will start with the fra-eng (French-English) translation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "import torch\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter\n",
    "from torchtext.vocab import vocab\n",
    "from random import shuffle\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from collections import Counter\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read raw texts and perform train-val-test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read all lines and shuffle\n",
    "file = open(\"datasets/fra-eng/fra.txt\", \"r\")\n",
    "all_lines = file.readlines()\n",
    "shuffle(all_lines)\n",
    "## Train-Val-Test split\n",
    "train_ratio, val_ratio = 0.8, 0.1\n",
    "train_end = int(len(all_lines)*train_ratio)\n",
    "val_end = int(len(all_lines)*(train_ratio+val_ratio))\n",
    "train_raw = all_lines[:train_end]\n",
    "val_raw = all_lines[train_end:val_end]\n",
    "test_raw = all_lines[val_end:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocab, Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabs(lines, source_tokenizer, target_tokenizer):\n",
    "    source_counter = Counter()\n",
    "    target_counter = Counter()\n",
    "    for line in lines:\n",
    "        parts = line.split(\"\\t\") #source, target and note are separated by tab\n",
    "        source_counter.update(source_tokenizer(parts[0].lower()))\n",
    "        target_counter.update(target_tokenizer(parts[1].lower()))\n",
    "    source_vocab = vocab(source_counter, specials=[\"<unk>\",\"<pad>\", \"<bos>\", \"<eos>\"])\n",
    "    target_vocab = vocab(target_counter, specials=[\"<unk>\",\"<pad>\", \"<bos>\", \"<eos>\"])\n",
    "    source_vocab.set_default_index(source_vocab['<unk>'])\n",
    "    target_vocab.set_default_index(target_vocab['<unk>'])    \n",
    "    return source_vocab, target_vocab\n",
    "\n",
    "def process_data(lines, source_tokenizer, target_tokenizer, source_vocab, target_vocab):\n",
    "    data=[]\n",
    "    for line in lines:\n",
    "        source, target, _ = line.split(\"\\t\")\n",
    "        source_tensor = torch.tensor(source_vocab(source_tokenizer(source.lower())))\n",
    "        target_tensor = torch.tensor(target_vocab(target_tokenizer(target.lower())))\n",
    "        data.append((source_tensor, target_tensor))\n",
    "    return data\n",
    "\n",
    "def generate_batch(data_batch, source_vocab, target_vocab):\n",
    "    source_batch = []\n",
    "    target_batch = []\n",
    "    for source, target in data_batch:\n",
    "        source_batch.append(torch.cat([torch.tensor(source_vocab[\"<bos>\"]), source, torch.tensor([source_vocab[\"<eos>\"]])], dim=0))\n",
    "        target_batch.append(torch.cat([torch.tensor([target_vocab[\"<bos>\"]]), target, torch.tensor([target_vocab[\"<eos>\"]])], dim=0))\n",
    "    source_batch = pad_sequence(source_batch, padding_value=source_vocab[\"<pad>\"])\n",
    "    target_batch = pad_sequence(target_batch, padding_value=target_vocab[\"<pad>\"])\n",
    "    return source_batch, target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use tokenizers from spacy\n",
    "en_tokenizer = get_tokenizer(\"spacy\", language=\"en_core_web_sm\")\n",
    "fr_tokenizer = get_tokenizer(\"spacy\", language=\"fr_core_news_sm\")\n",
    "## Get source target vocabs\n",
    "en_vocab, fr_vocab = get_vocabs(train_raw, en_tokenizer, fr_tokenizer)\n",
    "## Get source tartget token ids\n",
    "train_data = process_data(train_raw, en_tokenizer, fr_tokenizer, en_vocab, fr_vocab)\n",
    "val_data = process_data(val_raw, en_tokenizer, fr_tokenizer, en_vocab, fr_vocab)\n",
    "test_data = process_data(test_raw, en_tokenizer, fr_tokenizer, en_vocab, fr_vocab)\n",
    "## Get train, val, test dataloader\n",
    "collator = lambda x: generate_batch(x, en_vocab, fr_vocab)\n",
    "bsz = 16\n",
    "train_iter = DataLoader(train_data, batch_size=bsz, shuffle=True, collate_fn=collator,num_workers=8)\n",
    "val_iter = DataLoader(val_data, batch_size=bsz, shuffle=False, collate_fn=collator, num_workers=8)\n",
    "test_iter = DataLoader(test_data, batch_size=bsz, shuffle=False, collate_fn=collator, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Seq2Seq Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn \n",
    "import torch.nn.functional as F \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "\n",
    "        self.embedding = nn.Embedding(self.input_dim, self.emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
    "        self.fc = nn.Linear(2*enc_hid_dim, dec_hid_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embeded = self.embedding(src)\n",
    "        outputs, hidden = self.rnn(embeded)\n",
    "        hidden = torch.tanh(self.fc(torch.cat([hidden[-2,:,:],hidden[-1,:,:]],dim=-1)))\n",
    "\n",
    "        return outputs, hidden\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self,enc_hid_dim, dec_hid_dim, attn_dim):\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "\n",
    "        self.attn_in = (enc_hid_dim*2) + dec_hid_dim \n",
    "        self.attn = nn.Linear(self.attn_in, attn_dim)\n",
    "\n",
    "    def forward(self, decoder_hidden, encoder_outputs):\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "\n",
    "        repeated_decoder_hidden = decoder_hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        encdoer_outputs = encoder_outputs.permute(1,0,2)\n",
    "\n",
    "        energy = torch.tanh(\n",
    "            self.attn(torch.cat([repeated_decoder_hidden, encoder_outputs], dim=-1))\n",
    "        )\n",
    "        attention = torch.sum(energy, dim=-1)\n",
    "        return F.softmax(attention, dim=-1)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
    "        super().__init__()\n",
    "\n",
    "        self.emb_dim = emb_dim\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention\n",
    "\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(enc_hid_dim*2+emb_dim, dec_hid_dim)\n",
    "        self.out = nn.Linear(self.attention.attn_in+emb_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def _weighted_encoder_rep(self, decoder_hidden, encoder_outputs):\n",
    "        a = self.attention(decoder_hidden, encoder_outputs)\n",
    "        a = a.unsqueeze(1)\n",
    "\n",
    "        encoder_outputs = encoder_outputs.permute(1,0,2)\n",
    "        weighted_encoder_rep = torch.bmm(a, encoder_outputs)\n",
    "        weighted_encoder_rep = weighted_encoder_rep.permute(1,0,2)\n",
    "\n",
    "        return weighted_encoder_rep\n",
    "    \n",
    "    def forward(self, input, decoder_hidden, encoder_outputs):\n",
    "        input = input.unsqueeze(0)\n",
    "        embeded = self.dropout(self.embedding(input))\n",
    "\n",
    "        weighted_encoder_rep = self._weighted_encoder_rep(decoder_hidden, encoder_outputs)\n",
    "\n",
    "        rnn_input = torch.cat((embeded, weighted_encoder_rep),dim=2)\n",
    "\n",
    "        output, decoder_hidden = self.rnn(rnn_input, decoder_hidden.unsqueeze(0))\n",
    "\n",
    "        embeded = embeded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        weighted_encoder_rep = weighted_encoder_rep.squeeze(0)\n",
    "\n",
    "        output = self.out(torch.cat((output, weighted_encoder_rep, embeded),dim=1))\n",
    "        return output, decoder_hidden.squeeze(0)\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio):\n",
    "        batch_size = src.shape[1]\n",
    "        max_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "\n",
    "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
    "\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "\n",
    "        output = trg[0,:]\n",
    "\n",
    "        for t in range(1, max_len):\n",
    "            output, hidden = self.decoder(output, hidden, encoder_outputs)\n",
    "            outputs[t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.max(1)[1] # tensor.max() returns tuple of maxiums and idmax\n",
    "            output = (trg[t] if teacher_force else top1)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([2, 5, 8]),\n",
       "indices=tensor([2, 2, 2]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0638b84c441d23f3bf1e5bbb68dbbbae5f508c99744b50e7a508082753ac4090"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
