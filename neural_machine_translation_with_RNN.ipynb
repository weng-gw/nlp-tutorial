{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Machine Translation with RNN\n",
    "\n",
    "We apply RNN to the language translation task, which is a typical seq to seq learning tastk. We will use a Encoder-Decoder architecture, where we use RNN models for both Encoder and Decoder parts. \n",
    "\n",
    "We will use the data from [the Tatoeba Project](http://www.manythings.org/anki/) and specifically, we will start with the fra-eng (French-English) translation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "import torch\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter\n",
    "from torchtext.vocab import vocab\n",
    "from random import shuffle, sample\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from collections import Counter\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read raw texts and perform train-val-test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197463\n"
     ]
    }
   ],
   "source": [
    "## Read all lines and shuffle\n",
    "file = open(\"datasets/fra-eng/fra.txt\", \"r\")\n",
    "all_lines = file.readlines()\n",
    "shuffle(all_lines)\n",
    "#all_lines = sample(all_lines,100000)\n",
    "print(len(all_lines))\n",
    "## Train-Val-Test split\n",
    "train_ratio, val_ratio = 0.8, 0.1\n",
    "train_end = int(len(all_lines)*train_ratio)\n",
    "val_end = int(len(all_lines)*(train_ratio+val_ratio))\n",
    "train_raw = all_lines[:train_end]\n",
    "val_raw = all_lines[train_end:val_end]\n",
    "test_raw = all_lines[val_end:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocab, Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabs(lines, source_tokenizer, target_tokenizer):\n",
    "    source_counter = Counter()\n",
    "    target_counter = Counter()\n",
    "    for line in lines:\n",
    "        parts = line.split(\"\\t\") #source, target and note are separated by tab\n",
    "        source_counter.update(source_tokenizer(parts[0].lower()))\n",
    "        target_counter.update(target_tokenizer(parts[1].lower()))\n",
    "    source_vocab = vocab(source_counter, specials=[\"<unk>\",\"<pad>\", \"<bos>\", \"<eos>\"])\n",
    "    target_vocab = vocab(target_counter, specials=[\"<unk>\",\"<pad>\", \"<bos>\", \"<eos>\"])\n",
    "    source_vocab.set_default_index(source_vocab['<unk>'])\n",
    "    target_vocab.set_default_index(target_vocab['<unk>'])    \n",
    "    return source_vocab, target_vocab\n",
    "\n",
    "def process_data(lines, source_tokenizer, target_tokenizer, source_vocab, target_vocab):\n",
    "    data=[]\n",
    "    for line in lines:\n",
    "        source, target, _ = line.split(\"\\t\")\n",
    "        source_tensor = torch.tensor(source_vocab(source_tokenizer(source.lower())))\n",
    "        target_tensor = torch.tensor(target_vocab(target_tokenizer(target.lower())))\n",
    "        data.append((source_tensor, target_tensor))\n",
    "    return data\n",
    "\n",
    "def generate_batch(data_batch, source_vocab, target_vocab):\n",
    "    source_batch = []\n",
    "    target_batch = []\n",
    "    for source, target in data_batch:\n",
    "        source_batch.append(torch.cat([torch.tensor([source_vocab[\"<bos>\"]]), source, torch.tensor([source_vocab[\"<eos>\"]])], dim=0))\n",
    "        target_batch.append(torch.cat([torch.tensor([target_vocab[\"<bos>\"]]), target, torch.tensor([target_vocab[\"<eos>\"]])], dim=0))\n",
    "    source_batch = pad_sequence(source_batch, padding_value=source_vocab[\"<pad>\"]).pin_memory()\n",
    "    target_batch = pad_sequence(target_batch, padding_value=target_vocab[\"<pad>\"]).pin_memory()\n",
    "    return source_batch, target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use tokenizers from spacy\n",
    "en_tokenizer = get_tokenizer(\"spacy\", language=\"en_core_web_sm\")\n",
    "fr_tokenizer = get_tokenizer(\"spacy\", language=\"fr_core_news_sm\")\n",
    "## Get source target vocabs\n",
    "en_vocab, fr_vocab = get_vocabs(train_raw, en_tokenizer, fr_tokenizer)\n",
    "## Get source tartget token ids\n",
    "train_data = process_data(train_raw, en_tokenizer, fr_tokenizer, en_vocab, fr_vocab)\n",
    "val_data = process_data(val_raw, en_tokenizer, fr_tokenizer, en_vocab, fr_vocab)\n",
    "test_data = process_data(test_raw, en_tokenizer, fr_tokenizer, en_vocab, fr_vocab)\n",
    "## Get train, val, test dataloader\n",
    "collator = lambda x: generate_batch(x, en_vocab, fr_vocab)\n",
    "bsz = 256\n",
    "train_iter = DataLoader(train_data, batch_size=bsz, shuffle=True, collate_fn=collator)\n",
    "val_iter = DataLoader(val_data, batch_size=bsz, shuffle=False, collate_fn=collator)\n",
    "test_iter = DataLoader(test_data, batch_size=bsz, shuffle=False, collate_fn=collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Seq2Seq Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn \n",
    "import torch.nn.functional as F \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "\n",
    "        self.embedding = nn.Embedding(self.input_dim, self.emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
    "        self.fc = nn.Linear(2*enc_hid_dim, dec_hid_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embeded = self.embedding(src)\n",
    "        outputs, hidden = self.rnn(embeded)\n",
    "        hidden = torch.tanh(self.fc(torch.cat([hidden[-2,:,:],hidden[-1,:,:]],dim=-1)))\n",
    "\n",
    "        return outputs, hidden\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self,enc_hid_dim, dec_hid_dim, attn_dim):\n",
    "        super().__init__()\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "\n",
    "        self.attn_in = (enc_hid_dim*2) + dec_hid_dim \n",
    "        self.attn = nn.Linear(self.attn_in, attn_dim)\n",
    "\n",
    "    def forward(self, decoder_hidden, encoder_outputs):\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "\n",
    "        repeated_decoder_hidden = decoder_hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        encoder_outputs = encoder_outputs.permute(1,0,2)\n",
    "\n",
    "        energy = torch.tanh(\n",
    "            self.attn(torch.cat([repeated_decoder_hidden, encoder_outputs], dim=-1))\n",
    "        )\n",
    "        attention = torch.sum(energy, dim=-1)\n",
    "        return F.softmax(attention, dim=-1)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
    "        super().__init__()\n",
    "\n",
    "        self.emb_dim = emb_dim\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention\n",
    "\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(enc_hid_dim*2+emb_dim, dec_hid_dim)\n",
    "        self.out = nn.Linear(self.attention.attn_in+emb_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def _weighted_encoder_rep(self, decoder_hidden, encoder_outputs):\n",
    "        a = self.attention(decoder_hidden, encoder_outputs)\n",
    "        a = a.unsqueeze(1)\n",
    "\n",
    "        encoder_outputs = encoder_outputs.permute(1,0,2)\n",
    "        weighted_encoder_rep = torch.bmm(a, encoder_outputs)\n",
    "        weighted_encoder_rep = weighted_encoder_rep.permute(1,0,2)\n",
    "\n",
    "        return weighted_encoder_rep\n",
    "    \n",
    "    def forward(self, input, decoder_hidden, encoder_outputs):\n",
    "        input = input.unsqueeze(0)\n",
    "        embeded = self.dropout(self.embedding(input))\n",
    "\n",
    "        weighted_encoder_rep = self._weighted_encoder_rep(decoder_hidden, encoder_outputs)\n",
    "\n",
    "        rnn_input = torch.cat((embeded, weighted_encoder_rep),dim=2)\n",
    "\n",
    "        output, decoder_hidden = self.rnn(rnn_input, decoder_hidden.unsqueeze(0))\n",
    "\n",
    "        embeded = embeded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        weighted_encoder_rep = weighted_encoder_rep.squeeze(0)\n",
    "\n",
    "        output = self.out(torch.cat((output, weighted_encoder_rep, embeded),dim=1))\n",
    "        return output, decoder_hidden.squeeze(0)\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        batch_size = src.shape[1]\n",
    "        max_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "\n",
    "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
    "\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "\n",
    "        output = trg[0,:]\n",
    "\n",
    "        for t in range(1, max_len):\n",
    "            output, hidden = self.decoder(output, hidden, encoder_outputs)\n",
    "            outputs[t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.max(1)[1] # tensor.max() returns tuple of maxiums and idmax\n",
    "            output = (trg[t] if teacher_force else top1)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(en_vocab)\n",
    "emb_dim = 32\n",
    "enc_hid_dim = 64\n",
    "dec_hid_dim = 64\n",
    "dropout = 0.8\n",
    "encoder = Encoder(input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout)\n",
    "attn_dim = 8\n",
    "attention = Attention(enc_hid_dim, dec_hid_dim, attn_dim)\n",
    "output_dim = len(fr_vocab)\n",
    "decoder = Decoder(output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention)\n",
    "\n",
    "##device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")  ## Only works on M-Series Mac\n",
    "device = torch.device(\"cuda\")## Only works on NVIDIA devices\n",
    "model = Seq2Seq(encoder, decoder,device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(14527, 32)\n",
       "    (rnn): GRU(32, 64, bidirectional=True)\n",
       "    (fc): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (dropout): Dropout(p=0.8, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): Attention(\n",
       "      (attn): Linear(in_features=192, out_features=8, bias=True)\n",
       "    )\n",
       "    (embedding): Embedding(24739, 32)\n",
       "    (rnn): GRU(160, 64)\n",
       "    (out): Linear(in_features=224, out_features=24739, bias=True)\n",
       "    (dropout): Dropout(p=0.8, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m: nn.Module):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "\n",
    "\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Evaluation, Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, iterator, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    for i, (src, trg) in enumerate(iterator):\n",
    "        src, trg = src.to(device), trg.to(device)\n",
    "        output = model(src, trg)\n",
    "\n",
    "        output = output[1:,].view(-1, output.shape[-1])\n",
    "        trg = trg[1:].view(-1)\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss/len(iterator)\n",
    "\n",
    "def evaluate_step(model, iterator, criterion):\n",
    "    model.eval\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    for i, (src, trg) in enumerate(iterator):\n",
    "        src, trg = src.to(device), trg.to(device)\n",
    "        output = model(src, trg)\n",
    "\n",
    "        output = output[1:,].view(-1, output.shape[-1])\n",
    "        trg = trg[1:].view(-1)\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss/len(iterator)\n",
    "\n",
    "\n",
    "def train(model, train_iter, val_iter, n_epochs, ignore_index, lr=0.002, clip=1):\n",
    "    optimizer  = optim.Adam(model.parameters(),lr=lr)\n",
    "    loss = nn.CrossEntropyLoss(ignore_index = ignore_index)\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss = train_step(model, train_iter, optimizer, loss, clip)\n",
    "        val_loss = evaluate_step(model, val_iter, loss)\n",
    "        print(f\"Epoch: {epoch+1}-----------------------------------------------------\")\n",
    "        print(f\"\\tTrain Loss: {train_loss} | Train PPL:{math.exp(train_loss)}\")\n",
    "        print(f\"\\tVal.  Loss: {val_loss} | Val. PPL:{math.exp(val_loss)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1-----------------------------------------------------\n",
      "\tTrain Loss: 1.7827761709497199 | Train PPL:5.946341585950041\n",
      "\tVal.  Loss: 2.2731602558722863 | Val. PPL:9.710038583432159\n",
      "Epoch: 2-----------------------------------------------------\n",
      "\tTrain Loss: 1.712539669186552 | Train PPL:5.54302105650506\n",
      "\tVal.  Loss: 2.2463907996813455 | Val. PPL:9.453554418052404\n",
      "Epoch: 3-----------------------------------------------------\n",
      "\tTrain Loss: 1.6871250995154519 | Train PPL:5.403922612126288\n",
      "\tVal.  Loss: 2.27739780377119 | Val. PPL:9.75127264097394\n",
      "Epoch: 4-----------------------------------------------------\n",
      "\tTrain Loss: 1.6572673758642573 | Train PPL:5.244958743076166\n",
      "\tVal.  Loss: 2.2428354299985447 | Val. PPL:9.42000321608532\n",
      "Epoch: 5-----------------------------------------------------\n",
      "\tTrain Loss: 1.6363205080279255 | Train PPL:5.136235961684595\n",
      "\tVal.  Loss: 2.2248168740517054 | Val. PPL:9.251788406242223\n",
      "Epoch: 6-----------------------------------------------------\n",
      "\tTrain Loss: 1.6103219534586934 | Train PPL:5.004422159520178\n",
      "\tVal.  Loss: 2.226977664690751 | Val. PPL:9.271801197964702\n",
      "Epoch: 7-----------------------------------------------------\n",
      "\tTrain Loss: 1.5678516045743207 | Train PPL:4.796332697632871\n",
      "\tVal.  Loss: 2.2439258969747105 | Val. PPL:9.43028102129296\n",
      "Epoch: 8-----------------------------------------------------\n",
      "\tTrain Loss: 1.5570617543840872 | Train PPL:4.744859181508414\n",
      "\tVal.  Loss: 2.2168827454249063 | Val. PPL:9.178673960256846\n",
      "Epoch: 9-----------------------------------------------------\n",
      "\tTrain Loss: 1.5469918675407237 | Train PPL:4.6973187515642785\n",
      "\tVal.  Loss: 2.197826324365078 | Val. PPL:9.005417353034305\n",
      "Epoch: 10-----------------------------------------------------\n",
      "\tTrain Loss: 1.5378659084005264 | Train PPL:4.654646222604937\n",
      "\tVal.  Loss: 2.211527561530089 | Val. PPL:9.12965185164695\n"
     ]
    }
   ],
   "source": [
    "train(model, train_iter,val_iter, 10, fr_vocab[\"<pad>\"],0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"models/MNT_en-fr_v1.pkl\")\n",
    "#torch.save([en_vocab, fr_vocab], \"models/MNT_en-fr_vocab.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.metrics import bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, src, src_tokenizer, src_vocab, trg_vocab, num_steps, device):\n",
    "    model.eval()\n",
    "    src_tokens = torch.tensor(src_vocab(src_tokenizer(src.lower())))\n",
    "    src_input = torch.cat([torch.tensor([src_vocab[\"<bos>\"]]), src_tokens, torch.tensor([src_vocab[\"<eos>\"]])],dim=0)\n",
    "    src_input = src_input.unsqueeze(1).to(device)\n",
    "    encoder_outputs, hidden = model.encoder(src_input)\n",
    "    dec_input = torch.tensor([trg_vocab[\"<bos>\"]]).to(device)\n",
    "    output_seq = []\n",
    "    for _ in range(num_steps):\n",
    "        Y, hidden = model.decoder(dec_input, hidden, encoder_outputs)\n",
    "        dec_input = Y.argmax(dim=-1)\n",
    "        pred = dec_input.squeeze().type(torch.int32).item()\n",
    "        if pred==trg_vocab[\"<eos>\"]:\n",
    "            break\n",
    "        output_seq.append(pred)\n",
    "    return output_seq, trg_vocab.lookup_tokens(output_seq), \" \".join(trg_vocab.lookup_tokens(output_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Case 1:\n",
      "Source text: I haven't left yet.\n",
      "Target text: ['je', 'ne', 'suis', 'pas', 'encore', 'parti', '.']\n",
      "Translation: ['je', \"n'\", 'ai', 'ai', 'encore', 'encore', 'encore', '.']\n",
      "Test Case 2:\n",
      "Source text: Tom is training.\n",
      "Target text: ['tom', \"s'\", 'entraã', '®', 'ne', '.']\n",
      "Translation: ['tom', \"s'\", 'entraã', '®', 't', '.']\n",
      "Test Case 3:\n",
      "Source text: Why did you try to run away?\n",
      "Target text: ['pourquoi', 'avez', '-vous', 'essayã', '©', 'de', 'vous', 'enfuirâ€¯', '?']\n",
      "Translation: ['pourquoi', 'as', '-', 'tu', 'essayã', '©', 'de', 'ã', '\\xa0 ', 'enfuirâ€¯', '?']\n",
      "Test Case 4:\n",
      "Source text: Do you still believe I killed my brother?\n",
      "Target text: ['crois', '-', 'tu', 'toujours', 'que', \"j'\", 'aie', 'tuã', '©', 'mon', 'frã¨re', '?']\n",
      "Translation: ['croyez', '-vous', 'que', 'que', \"j'\", 'ai', 'tuã', '©', 'mon', 'frã¨re', '?']\n",
      "Test Case 5:\n",
      "Source text: Tom found that.\n",
      "Target text: ['tom', 'a', 'trouvã', '©', 'cela', '.']\n",
      "Translation: ['tom', 'a', 'trouvã', '©', 'couvert', '.']\n"
     ]
    }
   ],
   "source": [
    "candidates=[]\n",
    "references=[]\n",
    "for i, line in enumerate(sample(test_raw,5)):\n",
    "    src, trg = line.split(\"\\t\")[:2]\n",
    "    pred_ids, pred_tokens, pred_txt = predict(model, src, en_tokenizer,en_vocab, fr_vocab, 50, device)\n",
    "    trg_tokens = fr_tokenizer(trg.lower())\n",
    "    candidates.append(pred_tokens)\n",
    "    references.append(trg_tokens)\n",
    "    print(f\"Test Case {i+1}:\")\n",
    "    print(f\"Source text: {src}\")\n",
    "    print(f\"Target text: {trg_tokens}\")\n",
    "    print(f\"Translation: {pred_tokens}\")\n",
    "    ##print(f\"BLEU Score: {bleu_score([pred_tokens], [trg_tokens])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English to Mandarin Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29371\n"
     ]
    }
   ],
   "source": [
    "## Read all lines and shuffle\n",
    "file = open(\"datasets/cmn-eng/cmn.txt\", \"r\", encoding=\"UTF-8\")\n",
    "all_lines = file.readlines()\n",
    "shuffle(all_lines)\n",
    "#all_lines = sample(all_lines,100000)\n",
    "print(len(all_lines))\n",
    "## Train-Val-Test split\n",
    "train_ratio, val_ratio = 0.8, 0.1\n",
    "train_end = int(len(all_lines)*train_ratio)\n",
    "val_end = int(len(all_lines)*(train_ratio+val_ratio))\n",
    "train_raw = all_lines[:train_end]\n",
    "val_raw = all_lines[train_end:val_end]\n",
    "test_raw = all_lines[val_end:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use tokenizers from spacy\n",
    "en_tokenizer = get_tokenizer(\"spacy\", language=\"en_core_web_sm\")\n",
    "zh_tokenizer = get_tokenizer(\"spacy\", language=\"zh_core_web_sm\")\n",
    "#zh_tokenizer = lambda x: list(x)\n",
    "## Get source target vocabs\n",
    "en_vocab, zh_vocab = get_vocabs(train_raw, en_tokenizer, zh_tokenizer)\n",
    "## Get source tartget token ids\n",
    "train_data = process_data(train_raw, en_tokenizer, zh_tokenizer, en_vocab, zh_vocab)\n",
    "val_data = process_data(val_raw, en_tokenizer, zh_tokenizer, en_vocab, zh_vocab)\n",
    "test_data = process_data(test_raw, en_tokenizer, zh_tokenizer, en_vocab, zh_vocab)\n",
    "## Get train, val, test dataloader\n",
    "collator = lambda x: generate_batch(x, en_vocab, zh_vocab)\n",
    "bsz = 256\n",
    "train_iter = DataLoader(train_data, batch_size=bsz, shuffle=True, collate_fn=collator)\n",
    "val_iter = DataLoader(val_data, batch_size=bsz, shuffle=False, collate_fn=collator)\n",
    "test_iter = DataLoader(test_data, batch_size=bsz, shuffle=False, collate_fn=collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(6518, 32)\n",
       "    (rnn): GRU(32, 64, bidirectional=True)\n",
       "    (fc): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (dropout): Dropout(p=0.8, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): Attention(\n",
       "      (attn): Linear(in_features=192, out_features=8, bias=True)\n",
       "    )\n",
       "    (embedding): Embedding(13607, 32)\n",
       "    (rnn): GRU(160, 64)\n",
       "    (out): Linear(in_features=224, out_features=13607, bias=True)\n",
       "    (dropout): Dropout(p=0.8, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = len(en_vocab)\n",
    "emb_dim = 32\n",
    "enc_hid_dim = 64\n",
    "dec_hid_dim = 64\n",
    "dropout = 0.8\n",
    "encoder = Encoder(input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout)\n",
    "attn_dim = 8\n",
    "attention = Attention(enc_hid_dim, dec_hid_dim, attn_dim)\n",
    "output_dim = len(zh_vocab)\n",
    "decoder = Decoder(output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention)\n",
    "\n",
    "##device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")  ## Only works on M-Series Mac\n",
    "device = torch.device(\"cuda\")## Only works on NVIDIA devices\n",
    "model = Seq2Seq(encoder, decoder,device).to(device)\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1-----------------------------------------------------\n",
      "\tTrain Loss: 6.1111171608385835 | Train PPL:450.8420970712251\n",
      "\tVal.  Loss: 5.490352710088094 | Val. PPL:242.3426684894301\n",
      "Epoch: 2-----------------------------------------------------\n",
      "\tTrain Loss: 5.2346368354299795 | Train PPL:187.66094216217022\n",
      "\tVal.  Loss: 5.226807316144307 | Val. PPL:186.1973841506843\n",
      "Epoch: 3-----------------------------------------------------\n",
      "\tTrain Loss: 4.94628021509751 | Train PPL:140.65079891700427\n",
      "\tVal.  Loss: 5.017607132593791 | Val. PPL:151.0494297512421\n",
      "Epoch: 4-----------------------------------------------------\n",
      "\tTrain Loss: 4.648452717324962 | Train PPL:104.42328816892052\n",
      "\tVal.  Loss: 4.861856301625569 | Val. PPL:129.2639323804961\n",
      "Epoch: 5-----------------------------------------------------\n",
      "\tTrain Loss: 4.359402013861614 | Train PPL:78.21035173056435\n",
      "\tVal.  Loss: 4.721812009811401 | Val. PPL:112.37168689891975\n",
      "Epoch: 6-----------------------------------------------------\n",
      "\tTrain Loss: 4.073651383752408 | Train PPL:58.77116736761745\n",
      "\tVal.  Loss: 4.577341477076213 | Val. PPL:97.25549425287345\n",
      "Epoch: 7-----------------------------------------------------\n",
      "\tTrain Loss: 3.745949685573578 | Train PPL:42.34920655797084\n",
      "\tVal.  Loss: 4.434635639190674 | Val. PPL:84.32139587836139\n",
      "Epoch: 8-----------------------------------------------------\n",
      "\tTrain Loss: 3.4268765501354053 | Train PPL:30.78035156269313\n",
      "\tVal.  Loss: 4.3535828193028765 | Val. PPL:77.75655213199914\n",
      "Epoch: 9-----------------------------------------------------\n",
      "\tTrain Loss: 3.1002474867779277 | Train PPL:22.203445660745945\n",
      "\tVal.  Loss: 4.2383824189503985 | Val. PPL:69.29566976918319\n",
      "Epoch: 10-----------------------------------------------------\n",
      "\tTrain Loss: 2.8028245749680893 | Train PPL:16.49116157006872\n",
      "\tVal.  Loss: 4.225566168626149 | Val. PPL:68.4132260079823\n",
      "Epoch: 11-----------------------------------------------------\n",
      "\tTrain Loss: 2.5549032636310742 | Train PPL:12.870054594952308\n",
      "\tVal.  Loss: 4.15854396422704 | Val. PPL:63.97830005515278\n",
      "Epoch: 12-----------------------------------------------------\n",
      "\tTrain Loss: 2.344128748644953 | Train PPL:10.424186683236426\n",
      "\tVal.  Loss: 4.136930008729299 | Val. PPL:62.610312986424205\n",
      "Epoch: 13-----------------------------------------------------\n",
      "\tTrain Loss: 2.196501155262408 | Train PPL:8.993491555795641\n",
      "\tVal.  Loss: 4.189113974571228 | Val. PPL:65.96431899638924\n",
      "Epoch: 14-----------------------------------------------------\n",
      "\tTrain Loss: 2.0526406207810277 | Train PPL:7.788440293560628\n",
      "\tVal.  Loss: 4.151700774828593 | Val. PPL:63.54197904684768\n",
      "Epoch: 15-----------------------------------------------------\n",
      "\tTrain Loss: 1.935785754867222 | Train PPL:6.92948679474509\n",
      "\tVal.  Loss: 4.202791392803192 | Val. PPL:66.87273883311003\n",
      "Epoch: 16-----------------------------------------------------\n",
      "\tTrain Loss: 1.8378063634685848 | Train PPL:6.28274108320518\n",
      "\tVal.  Loss: 4.2202191551526385 | Val. PPL:68.04839581196246\n",
      "Epoch: 17-----------------------------------------------------\n",
      "\tTrain Loss: 1.7685431177201478 | Train PPL:5.862306446588887\n",
      "\tVal.  Loss: 4.269202768802643 | Val. PPL:71.46463906275287\n",
      "Epoch: 18-----------------------------------------------------\n",
      "\tTrain Loss: 1.6953115981558096 | Train PPL:5.4483433944950885\n",
      "\tVal.  Loss: 4.2593055963516235 | Val. PPL:70.76082981163398\n",
      "Epoch: 19-----------------------------------------------------\n",
      "\tTrain Loss: 1.617865960235181 | Train PPL:5.042318318916847\n",
      "\tVal.  Loss: 4.327435950438182 | Val. PPL:75.74981108342485\n",
      "Epoch: 20-----------------------------------------------------\n",
      "\tTrain Loss: 1.568489028059918 | Train PPL:4.799390967341998\n",
      "\tVal.  Loss: 4.307125965754191 | Val. PPL:74.22685157346545\n"
     ]
    }
   ],
   "source": [
    "train(model, train_iter,val_iter, 20, zh_vocab[\"<pad>\"], lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Case 1:\n",
      "Source text: I think you're a really nice guy.\n",
      "Target text: ['我', '認為', '你', '真的', '是', '一', '個', '好人', '。']\n",
      "Translation: ['我', '觉得', '你', '真是', '个', '个', '好人', '。']\n",
      "Test Case 2:\n",
      "Source text: He is the same age as me.\n",
      "Target text: ['他', '和', '我', '同岁', '。']\n",
      "Translation: ['他', '對', '我', '同岁', '，', '我', '一样', '。', '。']\n",
      "Test Case 3:\n",
      "Source text: I think I shouldn't have asked Tom to do that.\n",
      "Target text: ['我', '想', '我', '不', '该', '让', '汤姆', '做', '那', '件', '事', '。']\n",
      "Translation: ['我', '認為', '我', '不', '該', '汤姆', '汤姆', '汤姆', '汤姆', '做', '。']\n",
      "Test Case 4:\n",
      "Source text: I wish I could go.\n",
      "Target text: ['我', '希望', '我', '可以', '去', '。']\n",
      "Translation: ['我', '願', '我', '能', '去', '。']\n",
      "Test Case 5:\n",
      "Source text: Tell him to mind his own business.\n",
      "Target text: ['告訴', '他', '別多', '管', '閒事', '。']\n",
      "Translation: ['他', '他', '向', '他', '的', '。', '。']\n"
     ]
    }
   ],
   "source": [
    "candidates=[]\n",
    "references=[]\n",
    "for i, line in enumerate(sample(test_raw,5)):\n",
    "    src, trg = line.split(\"\\t\")[:2]\n",
    "    pred_ids, pred_tokens, pred_txt = predict(model, src, en_tokenizer,en_vocab, zh_vocab, 50, device)\n",
    "    trg_tokens = zh_tokenizer(trg.lower())\n",
    "    candidates.append(pred_tokens)\n",
    "    references.append(trg_tokens)\n",
    "    print(f\"Test Case {i+1}:\")\n",
    "    print(f\"Source text: {src}\")\n",
    "    print(f\"Target text: {trg_tokens}\")\n",
    "    print(f\"Translation: {pred_tokens}\")\n",
    "    ##print(f\"BLEU Score: {bleu_score([pred_tokens], [trg_tokens])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28cdd387f5a19c1a019582c35e0554b941f30c5a12df8630a85901c6e2e83244"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
