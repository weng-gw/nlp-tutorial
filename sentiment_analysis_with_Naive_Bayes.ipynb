{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with Naive Bayes\n",
    "We apply Naive Bayes on the Twitter Sentiment Analysis data. To ease the problem, we will filter the dataset to include only positive and negative tweets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"datasets/twitter_sentiment_analysis/twitter_training.csv\"\n",
    "train_data = pd.read_csv(train_data_path,header=None)\n",
    "train_data.columns = [\"Tweet_ID\",\"entity\",\"sentiment\",\"Tweet_content\"]\n",
    "\n",
    "test_data_path = \"datasets/twitter_sentiment_analysis/twitter_validation.csv\"\n",
    "test_data = pd.read_csv(test_data_path,header=None)\n",
    "test_data.columns = [\"Tweet_ID\",\"entity\",\"sentiment\",\"Tweet_content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inlcude Only \"Positive\" and \"Negatvie\" twitts to form a binary classification problem\n",
    "## Label Positve as 1 and Negative as 0\n",
    "train_data = train_data[train_data.sentiment.isin([\"Positive\",\"Negative\"])]\n",
    "train_data[\"label\"] = train_data.sentiment.map({\"Positive\":1, \"Negative\":0})\n",
    "test_data = test_data[test_data.sentiment.isin([\"Positive\",\"Negative\"])]\n",
    "test_data[\"label\"] = test_data.sentiment.map({\"Positive\":1, \"Negative\":0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterNBClassifier:\n",
    "    def __init__(self,nlp):\n",
    "        self.nlp = nlp\n",
    "        self.loglikelihood={}\n",
    "        self.logprior = 0\n",
    "    def process_tweet_spacy(self, tweet, lemmetize=True):\n",
    "        # remove old sytle retweet text \"RT\"\n",
    "        tweet = str(tweet)\n",
    "        tweet2 = re.sub(r'^RT[\\s]+','', tweet)\n",
    "        # remove hyperlinks\n",
    "        tweet2 = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet2)\n",
    "        # remove hashtags\n",
    "        # only removing the hash # sign from the word\n",
    "        tweet2 = re.sub(r'#', '', tweet2)\n",
    "\n",
    "        doc = self.nlp(tweet2)\n",
    "        # remove stopworks and punctuation\n",
    "        if lemmetize:\n",
    "            return [token.lemma_.lower() for token in doc if (not token.is_stop) and (not token.is_punct) ]\n",
    "        else:\n",
    "            return [token.text.lower() for token in doc if (not token.is_stop) and (not token.is_punct) ]\n",
    "\n",
    "    def freq_counts(self, X, y):\n",
    "        freqs ={}\n",
    "        vocab = set()\n",
    "        neg_pos_count =[0, 0]\n",
    "        for tweet, label in zip(X,y):\n",
    "            tokenized_tweet = self.process_tweet_spacy(tweet)\n",
    "            for token in tokenized_tweet:\n",
    "                vocab.add(token)\n",
    "                neg_pos_count[label] += 1\n",
    "                pair = (label, token)\n",
    "                if pair in freqs:\n",
    "                    freqs[pair] += 1\n",
    "                else:\n",
    "                    freqs[pair] = 1    \n",
    "        return freqs, vocab, neg_pos_count\n",
    "    \n",
    "    def fit(self, X,y):\n",
    "        freqs, vocab, neg_pos_count = self.freq_counts(X,y)\n",
    "        V = len(vocab)\n",
    "        for word in vocab:\n",
    "            p_pos = (freqs.get((1, word),0)+1)/(neg_pos_count[1]+V)\n",
    "            p_neg = (freqs.get((0, word),0)+1)/(neg_pos_count[0]+V)\n",
    "            self.loglikelihood[word] = np.log(p_pos)-np.log(p_neg)\n",
    "        self.logprior = np.log(np.sum(y)) - np.log(np.sum(1-y))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        score = np.ones(len(X))*self.logprior\n",
    "        for i, tweet in enumerate(X):\n",
    "            tokenized_tweet = self.process_tweet_spacy(tweet)\n",
    "            for token in tokenized_tweet:\n",
    "                score[i] += self.loglikelihood.get(token, 0)\n",
    "        return np.where(score>0, 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "mynb = TwitterNBClassifier(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mynb.fit(train_data.Tweet_content, train_data.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = mynb.predict(test_data.Tweet_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest = test_data.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy over test data is 0.9134438305709024\n",
      "Precision over test data is 0.9259259259259259\n",
      "Recall over test data is 0.9025270758122743\n",
      "F1 score over test data is 0.9140767824497257\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy over test data is {accuracy_score(ytest, ypred)}\")\n",
    "print(f\"Precision over test data is {precision_score(ytest, ypred)}\")\n",
    "print(f\"Recall over test data is {recall_score(ytest, ypred)}\")\n",
    "print(f\"F1 score over test data is {f1_score(ytest, ypred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We achieve an accuracy score of >91% which is pretty good. Looks like for this dataset, the Naive Bayes classifier perfomrs much better than logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0638b84c441d23f3bf1e5bbb68dbbbae5f508c99744b50e7a508082753ac4090"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
